#+BLOG: wordpress
#+POSTID: 342
#+DATE: [2016-07-13 Wed 13:18]
#+OPTIONS: toc:nil num:nil todo:nil pri:nil tags:nil ^:nil tex:t
#+CATEGORY: Julia, Computations
#+TAGS:
#+DESCRIPTION:
#+LATEX_HEADER: \usepackage{stmaryrd}

#+TITLE: Savitzky-Golay filters & Julia

# Contains code to tangle
# --> To generate: C-c C-v t

I always have found that presented computations of the [[https://en.wikipedia.org/wiki/Savitzky%25E2%2580%2593Golay_filter][Savitzky-Golay]]
filter coefficients were over tricky. I present here a *simple
formula* and a possible implementation in [[http://julialang.org/][Julia]].

* Derivation of the formula

Given a polynomial of degree $d$ with values 
\begin{equation}
p(x_i)=\sum\limits_{j=0}^d c_j x_i^j
\end{equation}

defined for a window of size $2n+1$, $\{x_i,\ i\in\llbracket -n,n \rrbracket \}$

We want to find the value of its k-order derivative $p^{(k)}(x_0)$ in
the middle of the window assuming that the $c_j$ are founded solving a
least-squares problem:

\begin{equation}
\min\limits_{\mathbf{c}} \frac{1}{2} \| \mathbf{V} \mathbf{c} - \mathbf{y} \|_2^2
\end{equation}

where $\{y_i, i \in\llbracket -n,n \rrbracket \}$ is our signal values and $\mathbf{V}$ is the [[https://en.wikipedia.org/wiki/Polynomial_regression][Vandermonde matrix]]:

\begin{equation}
  \mathbf{V}=
  \left(
    \begin{array}{c|c|c}
      \vdots & \vdots & \vdots \\
      1 & x_i^{(j-1)} & x_i^d \\
      \vdots & \vdots & \vdots 
    \end{array}
  \right)
\end{equation}

using the *normal equation*

\begin{equation}
\mathbf{c}=(\mathbf{V}^t.\mathbf{V})^{-1}.\mathbf{V}^t.\mathbf{y}
\end{equation}

and a [[https://en.wikipedia.org/wiki/QR_decomposition][QR decomposition]], $\mathbf{V}=\mathbf{Q}.\mathbf{R}$ we get 

\begin{equation}
\mathbf{c}=\mathbf{R}^{-1}.\mathbf{Q}^t.\mathbf{y}
\end{equation}

now we can express the all the polynomial values $p(x_i)$ in a vector
$\mathbf{p}=\mathbf{V}.\mathbf{c}$. Lets rewrite this in matrix form:

\begin{equation}
\underbrace{\left(
    \begin{array}{c}
      p(x_{-n}) \\
     \vdots \\
        p(x_{0}) \\
      \vdots \\
      p(x_{+n}) 
    \end{array}
  \right)}\limits_{\mathbf{p}}=\underbrace{ 
  \left(
    \begin{array}{c|c|c}
      \vdots & \vdots & \vdots \\
      1 & x_i^{(j-1)} & x_i^d \\
      \vdots & \vdots & \vdots 
    \end{array}
  \right)}\limits_{\mathbf{V}}.\underbrace{\left(
    \begin{array}{c}
      c_0 \\
     \vdots \\
      c_n 
    \end{array}
  \right)}\limits_{\mathbf{c}}
\end{equation}

Now the "*big trick*" is to write the [[https://en.wikipedia.org/wiki/Taylor_series][Taylor series]] and to remember
that this formula is *exact* for polynomial functions:

\begin{equation}
\forall i,\ P(x_i) = \sum\limits_{j=0}^d \frac{x_i^j}{j!} P^{(j)}(x_0)
\end{equation}

Lets rewrite this in matrix form:
\begin{equation}
  \underbrace{
    \left(
      \begin{array}{c}
        p(x_{-n}) \\
        \vdots \\
        p(x_{0}) \\
        \vdots \\
        p(x_{n}) \\
      \end{array}
    \right)
  }_{\mathbf{p}} = 
  \underbrace{
    \left(
      \begin{array}{c|c|c}
        \vdots & \vdots & \vdots \\
        1 & \frac{x_i^{(j-1)}}{(j-1)!} &  \frac{x_i^{d}}{d!} \\
        \vdots & \vdots & \vdots 
      \end{array}
    \right)
    }_{\mathbf{T}}
 \underbrace{
   \left(
     \begin{array}{c}
       P^{(0)}(x_0) \\
       \vdots \\
       P^{(k)}(x_0) \\
       \vdots \\
       P^{(d)}(x_0) \\
     \end{array}
   \right) 
 }_{\mathbf{p^\delta}}
\end{equation}

With a good eye we see that $\mathbf{V}=\mathbf{T}.\mathbf{D}$ where $\mathbf{D}$ is a diagonal matrix:
\begin{equation}
\underbrace{ 
  \left(
    \begin{array}{c|c|c}
      \vdots & \vdots & \vdots \\
      1 & x_i^{(j-1)} & x_i^d \\
      \vdots & \vdots & \vdots 
    \end{array}
  \right)}\limits_{\mathbf{V}} = 
\underbrace{
    \left(
      \begin{array}{c|c|c}
        \vdots & \vdots & \vdots \\
        1 & \frac{x_i^{(j-1)}}{(j-1)!} &  \frac{x_i^{d}}{d!} \\
        \vdots & \vdots & \vdots 
      \end{array}
    \right)
    }_{\mathbf{T}}.\underbrace{\left(
    \begin{array}{ccc}
      1 & & \\
      & (j-1)! & \\
      & & d!
    \end{array}
  \right)}\limits_{\mathbf{D}}
 \end{equation}

That's all, know we only have to group pieces:
\begin{equation}
\mathbf{V}.\mathbf{c}=\mathbf{P}=\mathbf{T}.\mathbf{p^\delta}=\mathbf{V}.\mathbf{D}^{-1}.\mathbf{p^\delta}
\end{equation}

With the QR decomposition $\mathbf{V}=\mathbf{Q}.\mathbf{R}$ and $\mathbf{c}=\mathbf{R}^{-1}.\mathbf{Q}^t.\mathbf{y}$
we get:

\begin{equation}
\mathbf{Q}.\mathbf{Q}^t.\mathbf{y}=\mathbf{Q}.\mathbf{R}.\mathbf{D}^{-1}.\mathbf{p^\delta}
\end{equation}

using the fact that $\mathbf{Q}^t.\mathbf{Q}=\mathbf{I}$ we get:

\begin{equation}
\mathbf{Q}^t.\mathbf{y}=\mathbf{R}.\mathbf{D}^{-1}.\mathbf{p^\delta}
\end{equation}

hence we have:

\begin{equation}
\boxed{
\mathbf{p^\delta} = \mathbf{D}.\mathbf{R}^{-1}.\mathbf{Q}^t.\mathbf{y}
}
\end{equation}

which is our *final formula*.

* Symbolic computation to check that it works

We can use [[https://www.wolfram.com/mathematica/][mathematica]] to do a symbolic computation using
$\mathbf{p^\delta} =
\mathbf{D}.\mathbf{R}^{-1}.\mathbf{Q}^t.\mathbf{y}$. 

For a window width of $2n+1=7$ points and a polynomial of degree $d=2$
we get:




#+BEGIN_SRC mathematica :exports code :results latex
n = 3; d = 2;
V = Table[If[j != 0, i^j, 1], {i, -n, n}, {j, 0, d}];
{Qt, R} = QRDecomposition[V];
DD = DiagonalMatrix[Table[Factorial[i], {i, 0, d}]];
DD.Inverse[R].Qt // TeXForm
#+END_SRC

#+RESULTS: sg_mathematica
#+BEGIN_LaTeX
\left(
\begin{array}{ccccccc}
 -\frac{2}{21} & \frac{1}{7} & \frac{2}{7} & \frac{1}{3} & \frac{2}{7} & \frac{1}{7} & -\frac{2}{21} \\
 -\frac{3}{28} & -\frac{1}{14} & -\frac{1}{28} & 0 & \frac{1}{28} & \frac{1}{14} & \frac{3}{28} \\
 \frac{5}{42} & 0 & -\frac{1}{14} & -\frac{2}{21} & -\frac{1}{14} & 0 & \frac{5}{42}
\end{array}
\right)
#+END_LaTeX

\begin{equation}
\left(
\begin{array}{ccccccc}
 -\frac{2}{21} & \frac{1}{7} & \frac{2}{7} & \frac{1}{3} & \frac{2}{7} & \frac{1}{7} & -\frac{2}{21} \\
 -\frac{3}{28} & -\frac{1}{14} & -\frac{1}{28} & 0 & \frac{1}{28} & \frac{1}{14} & \frac{3}{28} \\
 \frac{5}{42} & 0 & -\frac{1}{14} & -\frac{2}{21} & -\frac{1}{14} & 0 & \frac{5}{42}
\end{array}
\right)
\end{equation}

The first row is the smoothing $P(0)$ filter, the second one the
smoothed first order derivative $P'(0)$ filter and the last one the smoothed
second order derivative $P''(0)$ filter.


* A Julia implementation

Here I present a direct implementation in julia.

We first initialize a Vandermonde matrix:

#+name: julia_V
#+begin_src julia
function vandermonde(halfWindow::Int, polyDeg::Int,T::Type=Float64)
    
    @assert halfWindow>=0
    @assert polyDeg>=0
    
    x=T[i for i in -halfWindow:halfWindow]

    n = polyDeg+1
    m = length(x)
    
    V = Array{T}(m, n)
    
    for i = 1:m
        V[i,1] = T(1)
    end
    for j = 2:n
        for i = 1:m
            V[i,j] = x[i] * V[i,j-1]
        end
    end

    return V
end
#+end_src

We then compute the filter coefficients with the presented formula.

*Attention* we return the transposed matrix because in Julia it is
more convenient to use SG[:,1] which is a julia vector. SG[1,:] would
be a 1xn julia matrix.

#+name: julia_SG
#+begin_src julia
function SG(halfWindow::Int, polyDeg::Int,T::Type=Float64)

    @assert 2*halfWindow>polyDeg
    
    V=vandermonde(halfWindow,polyDeg,T)
    Q,R=qr(V)
    SG=R\Q'

    for i in 1:size(SG,1)
        SG[i,:]*=factorial(i-1)
    end
    
# CAVEAT: returns the transposed matrix

    return SG'
end
#+end_src

The final step to use the filter is to provide function to do the [[https://en.wikipedia.org/wiki/Cross-correlation][cross-correlation]].

I do not want to talk too much about this subroutine because in a future
post I will show how to efficiently compute such kind of convolution. Here
we use a FFT, but with a short filter it is much more efficient (around
*10 times faster*) to use a direct computation. I will show how to implement
\begin{equation}
\gamma[k]=\sum\limits_i\alpha[i]\beta[k+\lambda i],\ with\ \lambda\in\mathbb{Z}^*
\end{equation}
which can be used to compute [[https://en.wikipedia.org/wiki/List_of_wavelet-related_transforms][discrete and stationary wavelet transform]] for instance.

One last thing, here we use *constant padding* to manage the boundaries.

#+name: julia_Conv
#+begin_src julia
function apply_filter{T}(filter::StridedVector{T},signal::StridedVector{T})

    @assert isodd(length(filter))

    halfWindow = round(Int,(length(filter)-1)/2)
    
    padded_signal = 
	    [signal[1]*ones(halfWindow);
         signal;
         signal[end]*ones(halfWindow)]

    filter_cross_signal = conv(filter[end:-1:1], padded_signal)

    return filter_cross_signal[2*halfWindow+1:end-2*halfWindow]
end
#+end_src

Finally I have included a small usage example. To see well the effect
of Savitzky-Golay filters, I have *over smoothed* with a *large window
width* $2.n+1$, $n=20$

#+name: julia_Example
#+begin_src julia
using Winston

s=readdlm("signal.txt")[:,1]

sg=SG(20,3) # halt-window, polynomal degree

#________________

smoothed=apply_filter(sg[:,1],s)

plot(s,"r")
oplot(smoothed)
title("Smoothed")
savefig("smoothed.png")

#________________

smoothed_d1=apply_filter(sg[:,2],s)

plot(smoothed_d1)
title("Smoothed derivative")
savefig("smoothed_d1.png")

#________________

smoothed_d2=apply_filter(sg[:,3],s)

plot(smoothed_d2)
title("Smoothed 2-derivative")
savefig("smoothed_d2.png")
#+end_src

Here is the resulting plots:

[[file:smoothed.png]]
[[file:smoothed_d1.png]]
[[file:smoothed_d2.png]]



#+begin_src julia :tangle yes :tangle sg.jl :noweb yes :exports none
# From 

<<julia_V>>

#________________________________________________________________

<<julia_SG>>

#________________________________________________________________

<<julia_Conv>>

#________________________________________________________________

<<julia_Example>>
#+end_src

# smoothed.png http://pixorblog.files.wordpress.com/2016/07/smoothed1.png
# smoothed_d1.png http://pixorblog.files.wordpress.com/2016/07/smoothed_d11.png
# smoothed_d2.png http://pixorblog.files.wordpress.com/2016/07/smoothed_d21.png
